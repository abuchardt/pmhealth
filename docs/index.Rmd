---
title: "Rasch in R"
author: "Ann-Sophie Buchardt"
format: 
  revealjs:
    navigation-mode: vertical
    pointer:
      pointerSize: 20
      color: '#ff4500'
revealjs-plugins:
  - pointer
filters:
  - reveal-auto-agenda
editor: visual
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

library(tidyverse)
library(readr)
library(DT)
```

# Introduction

## The Rasch model 

The Rasch model for polytomous items[^1] [@Andersen1977]: 

For person $v $ the probability of response $x$ on item $i$ is

$$
P(X_{vi}=x|\theta_v=\theta)=\frac{\exp(x\theta-\beta_{ix})}{\sum_{l=1}^{m_i}\exp(l\theta-\beta_{il})}
$$

where each item $i$ has a certain number of response categories, denoted by $m_i$. 

[^1]: Frequently referred to as the Rating Scale Model (RSM) or the Partial Credit Model (PCM)

## The Rasch model 

The Rasch model for polytomous items[^1] [@Andersen1977]: 

Model for the conditional probability that person $v = 1,\ldots,n$ with [ability $\theta_v$]{style="color: OrangeRed;"} would respond with category score $x$ on item $i = 1,\ldots, k$ with [difficulty $\beta_{ix}$]{style="color: OrangeRed;"}.







## Agenda

We demonstrate the functionality with an example using data from the The Skin Cancer Quality of Life ([SCQoL]{style="color: OrangeRed;"}) Questionnaire. 

Using these data we show [how to use R]{style="color: OrangeRed;"} to:

1) Estimate the Rasch model
2) Test the Rasch model
3) Test local dependence




## Overview of packages

@Linacre2022 identified 11 R packages capable of Rasch estimation and analysis.

We focus on

- `eRm`: does conditional ML (like RUMM2030)
- `TAM` an `ltm`: do MML (like ConQuest)

<mark style="background-color: #FFFF00">@ Karl hvad med `iarm` og `sirt`?</mark>


## Data and instrument
Data used in this workshop are disease-specific quality of life (QoL) questionnaires increasingly used to provide patient-reported outcome measures in both malignant and non-malignant disease.

### OBJECTIVE 
To create, validate and test the psychometrics of the Skin Cancer Quality of Life (SCQoL), which was designed to measure health-related QoL in patients with non-melanoma skin cancer affecting any area and undergoing any therapy.

## Patient Sample
These data contain...
<!--Of the 241 patients included, 82% (198/241) responded. Among the responders seven returned a blank questionnaire and declined to participate in the study, one patient was reported to have dementia, and two were reported dead by relatives. Patients having or having had MM (n = 3) and responders with more than one missing answer in the SCQoL (n = 8) were excluded. This provided 177/241 complete data sets (73%). Of the 177 included in the analysis, 81 (46%) were female and 96 (54%) male. The mean age was 71 years (range 41—95). The demographic characteristics of the patients participating in the study are shown in Table 1. Among the 177 answers only 3 questionnaires had one missing answer (for item 4, 8 and 9 respectively).-->

<!--Briefly, these data contain 757 complete responses to the Rosenberg Self-Esteem scale providing measures of global self-esteem (Rosenberg, Citation1989). The Rosenberg Self-Esteem scale used here consists of 10 items, five of which were positively worded and five negatively worded. All items on the scale were rated on a 4-point Likert scale with verbal anchors of Strongly Disagree (0), Disagree (1), Agree (2) and Strongly Agree (3). The frequency of responses to each category are reported in Table 1. The survey respondents were an average age was 22.4 years (SD ±  7.2 years) ranging from 16 to 75 years. The sample was 42% male, 48% female and the remaining 10% did not disclose sex. The respondents were 67.9% Caucasian, 12.8% Black, 2.4% Hispanic, 3.4% Asian, 1.7% Multiracial, 0.3% other races and 11.5% did not report race.-->


## Data management

We load data:

```{r, echo=FALSE}
library(haven)
SCQOL0 <- read_sas("scqol.sas7bdat")
```

```{r, eval=FALSE}
library(readr)
SCQOL0 <- read_csv("SCQOL.csv")
```

## Data management

The top six rows of our data are

```{r}
head(SCQOL0)
```

```{r, echo=FALSE, eval=FALSE}
DT::datatable(head(SCQOL0))
```

## Data management

Let's remove extreme total scores

```{r}
SCQOL <- SCQOL0 %>%
  na.omit(SCQoLQ1:SCQoLQ9) %>% # @Karl?
  filter(rowSums(.[4:12]) != 0 & rowSums(.[4:12]) != 3*9) 
```


## Data management

We create an object containing the items:

```{r}
items <- SCQOL %>%
  select(starts_with('SCQoLQ')) %>%
  select(1:9) 

head(items)
```

```{r, echo=FALSE, eval=FALSE}
DT::datatable(items)
```

```{r, echo=FALSE}
#kable(head(items), "html", booktabs = T) %>%
#  kableExtra::kable_styling(font_size = 22)
```





# 1. Estimate the Rasch model

## 1. Estimate the Rasch model

The `eRm` (extended Rasch modelling) package in R provides users with a considerable set of tools for Rasch modelling for scale evaluation and general modelling. 


## Conditional ML (like RUMM2030)

The `eRm` package uses conditional maximum likelihood ([CML]{style="color: OrangeRed;"}) for the dichotomous and polytomous models. 

CML [@Andersen1972] may be used to estimate models for which there are sufficient statistics available, as is the case for the family of Rasch models. That is, the item mean and person mean are sufficient statistics for the item and person measures, respectively. 

<!--Given this property of Rasch models, joint maximum likelihood (JML), or unconditional maximum likelihood (Wright & Stone, Citation1979), is also available and is employed by other Rasch software, such as WINSTEPS (Linacre, Citation2019b). However, JML cannot produce estimates for individuals with sum scores of zero or the maximum possible score (e.g., all items incorrect or all items correct), and the estimates produced are inconsistent and asymptotically normal (Andersen, Citation1973; Haberman, Citation1977, Citation2004). Additionally, the limitations of JML are due to the simultaneous estimation of item and person measures. On the other hand, CML does not have the same limitations as JML so the CML estimator can be viewed as a strength if considering different software for modeling. For instance, -->
<!--CML can produce consistent maximum likelihood estimates because it separates the item and person parameter estimates by conditioning the estimation of the likelihood function on the person sufficient statistics (@Andersen1972 de Ayala, Citation2009). -->


<!--The person measures are estimated in `eRm` in a step following the estimation of item measures using JML. This two-step process sidesteps the limitations of JML because (1) the parameters are not estimated simultaneously and (2) the item parameters estimated through CML can be treated as “known” (i.e., fixed) in order to estimate the person measures. The two-step process uses the advantages of both estimation procedures.-->

CML is used for the dichotomous (RM), partial credit (PCM) and rating scale (RSM) models.


## Estimate the Rasch model

<!--The scale is thought to measure a single underlying construct, or said another way, a unidimensional construct. The Rasch model was easily fit to these data and obtain the model results using the RM function (see below).-->
The Rasch model is fitted to data using the `PCM` function from the `eRm` package:

```{r}
# Load data
library(eRm)

# Fit Rasch model
fit <- PCM(items)
```


## Show results of estimation

```{r, eval=FALSE}
summary(fit)
```


```{r, echo=FALSE}
DT::datatable(summary(fit))
```

## Extract estimates

```{r}
names(fit)
```

. . .

Item (Category) Difficulty Parameters (eta): 

```{r}
fit$etapar
```

## Extract estimates

Item Easiness Parameters (beta):

```{r}
fit$betapar
```

## Note

The default settings fix the scale by fixing the sum of item easiness parameters to zero. The scale can easily be set by fixing the first easiness (beta) to 0 instead by using `sum0 = FALSE` as an argument in the function. These options provide users for flexibility in modelling and even greater flexibility can be achieved by utilizing the design matrix formulation.


## Thresholds

```{r}
(th <- thresholds(fit))
```

<mark style="background-color: #FFFF00">@ Karl Noget at bemærke/vise?</mark>

## Person parameters

```{r}
ppar <- person.parameter(fit)
```

```{r, eval=FALSE}
summary(ppar)
## S3 method for class 'ppar'
print(ppar)
## S3 method for class 'ppar'
plot(ppar, xlab = "Person Raw Scores",
   ylab = "Person Parameters (Theta)")
## S3 method for class 'ppar'
coef(ppar, extrapolated = TRUE, ...)
## S3 method for class 'ppar'
logLik(ppar)
## S3 method for class 'ppar'
confint(ppar, parm, level = 0.95, ...)
```


## Visualisation

The estimates for persons and items can be viewed in the person-item map using the `plotPImap` command. 

These figures help provide a representation of how the difficulty of items relates to the person-parameters for the fitted Rasch model. 

```{r, eval=FALSE}
plotPImap(fit, sorted = TRUE)
```

This map is created using `plotPImap(fit, sorted = TRUE)`, where the argument `sorted = TRUE` is not necessary, but will help with interpretation and identifying how items are distributed across the person parameter distributions.

## Visualisation - note

The `plotPImap` only needs the `PCM`-object, i.e., not necessarily the person parameters - they are automatically computed using `person.parameter` function by the `plotPImap` function.


## The person-item map

```{r, echo=FALSE}
plotPImap(fit, sorted = TRUE)
```

<mark style="background-color: #FFFF00">@ Karl Noget at bemærke?</mark>

## `WrightMap`

The WrightMap package provides functions to easily create these Wright Maps from item parameters and person estimates stored as R objects.

```{r}
#install.packages("WrightMap")
library(WrightMap)

wrightMap(fit$etapar, pp$theta.table)

```

## `WrightMap`

We can draw a simple item map by calling one of the item side functions. Currently there are three: `itemModern`, `itemClassic`, and `itemHist`.

The `itemModern` function is the default called by `wrightMap`.

```{r}
th.tab <- th$threshtable$`1`
itemModern(th.tab)
```

## `WrightMap`

The itemClassic function creates item sides inspired by text-based Wright Maps.

```{r}
itemClassic(th.tab)
```


## `WrightMap`

Finally, the `itemHist` function plots the items as a histogram.

```{r}
itemHist(th.tab)
```

## W

<mark style="background-color: #FFFF00">@ Karl hvad er multi proficiency?</mark>

```{r}
## Mock results
multi.proficiency <- data.frame(
  d1 = rnorm(1000, mean =  -0.5, sd = .5),
  d2 = rnorm(1000, mean =   0.0, sd = 1),
  d3 = rnorm(1000, mean =  +0.5, sd = 1),
  d4 = rnorm(1000, mean =   0.0, sd = .5),
  d5 = rnorm(1000, mean =  -0.5, sd = .75))
```


```{r}
personHist(multi.proficiency)
```

---

```{r}
personDens(multi.proficiency)
```

---

To use these plots in a Wright Map, use the item.side and person.side parameters.

```{r}
wrightMap(multi.proficiency, th.tab, 
          item.side = itemClassic, item.prop = 0.5,person.side = personDens)
```



## The item characteristic curves (ICCs)

A function that shows the relationship between ability ($\theta$) and the probability of answering an item correctly.

## ICCs

For dichotomous scales, the ICCs for all items can be obtained using the `plotICC` command. The command plots the ICC for each item on a separate window so that each item can be inspected individually. 

```{r, eval=FALSE, echo=FALSE}
par(mfrow = c(3,3))
plotICC(fit, ask = FALSE, mplot=FALSE)
```

<!-- @Karl: empirical ICC’s showing t↦P(yij=1|Sj=t) in stead of θ↦P(yij=1|θj=θ)?-->

All the ICCs can be plotted on the same window as well, using `plotjointICC`,

```{r, echo=FALSE, eval=FALSE}
par(mfrow=c(1,1))
plotjointICC(fit)
```

<!-- The ICC plot highlights how the items are distributed and ordered the item legend based on the difficulty. The difficulty in jointly plotting all the ICCs is that some of the curves can be difficult to see (e.g., item 7). -->


## The item [category]{style="color: OrangeRed;"} characteristic curves

For polytomnous scales, the `plotICC` function plots ICCs for each category within all items. 

```{r, eval=FALSE}
par(mfrow = c(3,3))
plotICC(fit, ask = FALSE, mplot=FALSE, legpos = FALSE)
```

<!--This plot shows the item characteristic curve for the item. The x-axis show the ability continuum the y-axis the response probability. The continuous line describes the probability to respond correctly to the problem given a level of ability. The difficulty of the item is the where the probability of a correct response equals 0.5. The option empICC="raw" also plots the relative frequencies of positive responses for each rawscore group at the position of the corresponding ability level. The blue dotted lines represent the 95% confidence level for the relative frequencies and are shown if options are provided if empCI = is specified.-->

## The item [category]{style="color: OrangeRed;"} characteristic curves

<mark style="background-color: #FFFF00">@ Karl Noget at bemærke?</mark>

```{r, echo=FALSE}
par(mfrow = c(3,3))
plotICC(fit, ask = FALSE, mplot=FALSE, legpos = FALSE)
```


# Exercise 1/3

## OBJECTIVE 

Create, validate, and test the psychometrics of the Actinic Keratosis Quality of Life (AKQoL) questionnaire, which was designed to measure health-related QoL in patients with actinic keratosis.

## Paper

Recreate [AKQOL](http://doi.wiley.com/10.1111/bjd.12036), Fig.2:

![](bjd12036_f2.gif)
    
## Exercise 1/3

1.1) Load data `AKQOL.csv` into R.

1.2) Fit the Rasch model using the `PCM()` function from the `eRm` package.

1.3) Show results of the RM estimation using the `summary()` function.

1.4) Examine the relationship between persons and items via the person-item map (`plotPImap()`).

1.5) Visualise the relationship between ability and probability of answering an item correctly using the `plotICC` function.

1.6) Experiment with the `WrigthMap` package.






# FIKA







# 2. Test the Rasch model


<!--# Model diagnostics-->


## 2. Test the Rasch model

The point of the Rasch model is very often to test whether the assumptions (unidimensionality, local independence, sufficiency, no DIF and monotonicity) are met.

Assumptions met $\Rightarrow$ Rasch model fit 

Rasch model misfit $\Rightarrow$ assumptions not met

## Testing Rasch in R

Testing the Rasch model in R can include the following steps

- <p class="fragment highlight-red">Andersen’s conditional Likelihood Ratio Test</p>
- Wald test
- subgroup homogeneity plots
- <p class="fragment highlight-red">Infit and Outfit</p>
- <p class="fragment highlight-red">ICC plots compared to empirical ICC</p>
- <p class="fragment highlight-red">tests for local dependence</p>
- <p class="fragment highlight-red">differential item functioning</p>


## 2) The Andersen likelihood ratio test

Using the `LRtest` command. The procedure tests for person homogeneity, which can be an indication of differential item function or violations of monotonicity, by estimating the item measures using two or three subgroups from the sample. Two or three subgroups are the only options, but this will likely meet most users’ needs. Invariance between the two or three sets of parameter estimates supports the model-data fit. The `LRtest` command produces the LR value (i.e., $\sim \chi^2$), degrees of freedom and p value. 

---

By default, two groups are formed based on raw scores above or below the median. Subgroups can also be created by the user based on a variable coded as a factor (e.g., sex) or based on the distribution of a quantitative variable. Because the test divides the sample into subgroups, a sufficiently large sample size is an important consideration to ensure that all subgroups are large enough.

## In R

```{r, error=TRUE}
# LR-test with a full raw-score split
lrt.full <- LRtest(fit, splitcr = "all.r")
```

---

```{r, warning=TRUE}
# LR-test with mean split, standard errors for beta's
lrt.mean <- LRtest(fit, splitcr = "mean")
```

---

```{r, warning=TRUE}
lrt.sex <- LRtest(fit, splitcr = SCQOL$Sex)
```

---

```{r, warning=TRUE}
splitvec <- as.numeric(SCQOL$Age > median(SCQOL$Age))
lrt.age <- LRtest(fit, splitcr = splitvec, se = TRUE)
```

---

```{r}
# goodness-of-fit plot for items 1, 14, 24, and 25
# additional 95 percent confidence ellipses, default style
plotGOF(lrt.age, beta.subset = (1:9), conf = list())
```

---

```{r, warning=TRUE}
# goodness-of-fit plot
# additional 95 percent control line with user specified style
plotGOF(lrt.age, ctrline = list(gamma = 0.95, col = "red", lty = "dashed"))
```

## Conclusion on Andersen's LR test

It is not implemented in an optimal way.




## Recall the item [category]{style="color: OrangeRed;"} characteristic curves

A function that shows the relationship between ability ($\theta$) and the probability of answering an item correctly.

```{r, eval=FALSE}
par(mfrow = c(3,3))
plotICC(fit, ask = FALSE, mplot=FALSE, legpos = FALSE)
```


## The item [category]{style="color: OrangeRed;"} characteristic curves

```{r, echo=FALSE}
par(mfrow = c(3,3))
plotICC(fit, ask = FALSE, mplot=FALSE, legpos = FALSE)
```

<!-- @Karl: empirical ICC’s showing t↦P(yij=1|Sj=t) in stead of θ↦P(yij=1|θj=θ)?-->

<!-- The ICC plot highlights how the items are distributed and ordered the item legend based on the difficulty. The difficulty in jointly plotting all the ICCs is that some of the curves can be difficult to see (e.g., item 7). -->



## ICC for polytomous items

<mark style="background-color: #FFFF00">@ Karl Hvad er pointen?</mark>

```{r, echo=FALSE}
efct <- Vectorize(function(theta, i) {
  x <- min(items):max(items)
  eta <- exp(theta * x - c(0, beta[, i]))
  pbs <- eta / sum(eta, na.rm=TRUE)
  sum(x * pbs, na.rm=TRUE)
})

mi <- apply(items, 2, max, na.rm = TRUE)
beta.vec <- - fit$betapar
rows <- do.call(c, lapply(1:9, function(i) 1:mi[i]))
cols <- do.call(c, lapply(1:9, function(i) rep(i, mi[i])))
beta <- matrix(NA, nrow = max(items), ncol = ncol(items))
for (i in 1:length(beta.vec)) {
  beta[rows[i], cols[i]] <- beta.vec[i]
}
```

```{r, echo=FALSE}
par(mfrow = c(3,3))
for (i in 1:9) {
  curve(efct(theta = x, i), -2, 2, 
        main = paste("Item: ", i),
        ylab = expression(E(X ~ "|" ~ theta ~ "=" ~ theta)),
        xlab = expression(theta),
        bty = "n")
  }
```

```{r, include=FALSE}
library(RASCHplot)
CICCplot(fit, which.item = "all", grid.items = TRUE)
```


## The conditional item characteristic curves (CICCs)

A Conditional ICC (CICC) is a curve describing the expected item mean as a function of the total score. It is possible to make an empirical CICC based on the observed data as both the empirical expected item score and the total scores can be calculated from the data. This empirical curve can then be compared to the model-based CICC to visualize item fit.

```{r, eval=FALSE}
library(RASCHplot)
CICCplot(fit)
```

## CICC

```{r, echo=FALSE, results=FALSE}
library(RASCHplot)
CICCplot(fit, observed = FALSE)[[1]] + 
  scale_color_manual(values=c("darkgrey")) + 
  guides(colour = guide_legend(title = ""))
```

## CICC

```{r, echo=FALSE, results=FALSE}
CICCplot(fit)[[1]] + 
  guides(colour = guide_legend(title = ""))
```

## Grouping of total scores (for CICC)

```{r}
tab <- table(rowSums(fit$X))
tab
```

```{r, eval=FALSE, echo=FALSE}
library(Publish)
table(acut(rowSums(fit$X)))
qu <- quantile(rowSums(fit$X), probs = seq(0, 1, length.out = 6))
table(cut(rowSums(fit$X), breaks = qu, include.lowest = TRUE))
```

. . .

```{r}
qu <- quantile(rowSums(fit$X, na.rm = TRUE), probs = seq(0, 1, length.out = 5))
cuts <- cut(rowSums(fit$X, na.rm = TRUE), breaks = qu, include.lowest = TRUE)
table(cuts)
```

. . .

```{r}
lower.cuts <- sapply(strsplit(levels(cuts), ","), "[[", 1)
lower.groups <- as.numeric(gsub("\\D", "", lower.cuts)) 
lower.groups
```

. . .

```{r, echo=TRUE, eval=FALSE}
CICCplot(fit, lower.groups = lower.groups)
```

## CICC with grouping

```{r, echo=FALSE, results=TRUE}
CICCplot(fit, lower.groups = lower.groups)[[1]] + 
  scale_x_continuous(breaks = c(lower.groups, max(rowSums(fit$X))))
```

## CICC with grouping 

```{r, echo=FALSE, fig.show='animate', interval=.5, aniopts="controls,loop", message=FALSE, results='hide'}
for (i in 1:ncol(items)) {
  pp <- CICCplot(fit, which.item = i, lower.groups = lower.groups)[[1]] + 
    scale_x_continuous(breaks = c(lower.groups, max(rowSums(fit$X)))) +
    scale_y_continuous(breaks = 0:3)
  print(pp)
  #Sys.sleep(2)
}
```

## CICC with grouping

```{r, echo=FALSE}
CICCplot(fit, which.item = 5, lower.groups = lower.groups)[[1]] + 
  scale_x_continuous(breaks = c(lower.groups, max(rowSums(fit$X))))
```




## INFIT and OUTFIT

Information-weighted mean square (INFIT) and unweighted mean square (OUTFIT) estimates are provided for each item and each person, which is customary in evaluating Rasch model-data fit. 
These estimates along with their $\chi^2$ values, degrees of freedom, p-value, and t-test statistics are available with the `itemfit` and `personfit` commands, respectively, for items and persons. The INFIT t test statistics can also be plotted for items or persons using the `plotPImap` command, in which users may plot with or without confidence intervals. This plot may be particularly helpful in examining many items or persons efficiently.


## Item fit statistics

The item fit information is obtained through a two-step process. First, we compute the person parameters along will all the residuals. Then, the investigation of the item fit statistics is a straightforward extension. The item fit statistics (i.e., INFIT/OUTFIT $t$ or MSQ) are obtained using

```{r, eval=FALSE}
pp <- person.parameter(fit)
itemfit(pp)
```

## Item fit statistics

```{r, echo=FALSE}
pp <- person.parameter(fit)
itemfit(pp)
```

## Item fit statistics

We cannot trust the P-values, because `Chisq` does not have a $\chi^2$-distribution. Nobody knows the asymptotic distribution of INFIT and OUTFIT. We need the R package `iarm` (item analysis in Rasch models):

```{r, eval=FALSE}
library(iarm)
out_infit(fit)
```

this output shows `*` whenever a p-value is smaller then 5%. 

---

```{r}
library(iarm)
out_infit(fit)
```

## Evaluating item fit using simulation

Simulate 1000 data sets based on $\hat\beta$ and $\hat\theta$
Look at empirical distribution of $\chi^2$ for item of interest

Load R package:

```{r}
library(RASCHplot)
```

Create data matrix:

```{r}
dat <- as.matrix(items)
```


```{r, echo=FALSE, eval=FALSE}
fit <- RASCHfits(method.item = "CML",
                 method.person = "MLE",
                 dat = dat)
beta <- fit$beta
theta <- fit$theta

stats <- RASCHstats(beta, theta, dat)
outfits <- data.frame(x = stats$Outfit,
                      y = rep(0, length(stats$Outfit)))
```

## Evaluating item fit using simulation

Simulate item responses and fit statistics:

```{r}
beta <- -fit$betapar
theta <- pp$theta.table$`Person Parameter`
outfits <- data.frame(x = out_infit(fit)$Outfit,
                      y = rep(0, 9))

x <- simRASCHstats(beta, theta,
                   method.item = "CML",
                   method.person = "MLE",
                   B = 100, model = "RMD")
```

## Evaluating item fit using simulation

::: {.panel-tabset}

### code

```{r, echo=FALSE}
theme_set(theme_minimal() + theme(legend.title = element_blank(),
                                  plot.title = element_text(size = 8, hjust = 0.5),
                                  text = element_text(size = 8)))
```

```{r, eval=FALSE}
plot(x) +
  geom_point(data = outfits, 
             colour = "black", size = 1.5) + 
  geom_text(data = outfits, aes(label = 1:nrow(outfits)), vjust = -2) 

plot(x, type = "Outfit", extreme = "max") +
  geom_point(data = outfits, 
             colour = "black", size = 1.5) + 
  geom_text(data = outfits, aes(label = 1:nrow(outfits)), vjust = -2) 
```

### output (min)

```{r, echo=FALSE}
plot(x) +
  geom_point(data = outfits, 
             colour = "black", size = 1.5) + 
  geom_text(data = outfits, aes(label = 1:nrow(outfits)), vjust = -2) 
```

### output (max)

```{r, echo=FALSE}
plot(x, type = "Outfit", extreme = "max") +
  geom_point(data = outfits, 
             colour = "black", size = 1.5) + 
  geom_text(data = outfits, aes(label = 1:nrow(outfits)), vjust = -2) 
```

:::


## Item-restscore

Item-total correlations and item-restscore correlations are routinely reported in classical test theory. Kreiner (2011) used the simple structure in the Rasch model to compute the expected values of the item-restscore correlation:

```{r, eval=FALSE}
item_restscore(fit)
```

---

```{r}
item_restscore(fit)
```









## Differential item functioning

```{r, eval=FALSE}
strat.vars <- list(Sex = SCQOL$Sex)
DIFplot(fit, which.item = 5, strat.vars = strat.vars, lower.groups = lower.groups)
```

---

```{r, echo=FALSE}
strat.vars <- list(Sex = SCQOL$Sex)
DIFplot(fit, which.item = 5, strat.vars = strat.vars, lower.groups = lower.groups)
```

---

```{r}
#DIFplot(fit, which.item = 5, strat.vars = strat.vars, lower.groups = lower.groups)[[1]] + 
#  geom_line(data = data.frame(spline(d, n=n*10)))
```




# Exercise 2/3

## Exercise 2/3

2.1) Anders's LR test

2.2) CICC

2.3) Item fit statistics

2.4) DIF




# 3. Testing local dependence

## 3. Testing local dependence

Testing local dependence can be done by removing an item, fitting the Rasch model to the remaining items, splitting with respect to the removed item. The general method for testing local dependence in IRT is Yens Q3

We use the `sirt` (supplementary IRT) package for this:

```{r}
library(sirt)
```

---

We fit a Rasch model using `sirt` and save estimates $\hat\beta$ of item parameters and estimate person locations $\hat\theta$ (we use Warms weighted MLE)
 
```{r, eval=FALSE, echo=FALSE}
itms <- as.matrix(items)
mod <- sirt::rasch.mml2(itms)
beta <- mod$item$b
mod.wle <- sirt::wle.rasch(dat = items , b = beta)
theta <- mod.wle$theta
```

```{r}
beta <- -fit$etapar
theta <- pp$thetapar$NAgroup1
```


and now we can calculate Yen’s Q3 statistic

```{r}
q3 <- sirt::Q3(dat = items, theta = theta , b = beta)
```

---

```{r, echo=FALSE}
corrplot::corrplot(q3$q3.matrix)
```

---

```{r}
q3 <- sirt::Q3(dat = items, theta = theta , b = beta)
```
 
Conventional interpretation: correlations should be close to zero. A large value is evidence of a problem with the scale, but since we do not know the asymptotic distribution we have to rely on a rule of thumb to decide when to reject model fit. 
An extensive simulation study indicated that "0.2 above the average" works well in many situations.



# Exercise 3/3

## Exercise 3/3

3.1) Yen's Q3 statistic

3.2)

3.3)

3.4)

# References

## References

<div id="refs"></div>





